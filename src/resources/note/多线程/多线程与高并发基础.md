# 工具介绍

**IDEA插件，字节码阅读器**

`https://www.jianshu.com/p/85fcc4676b36`

工具：对象在jvm中的信息

```xml

<dependencies>
<!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core -->
    <dependency>
        <groupId>org.openjdk.jol</groupId>
        <artifactId>jol-core</artifactId>
        <version>0.9</version>
    </dependency>
</dependencies>
```

# 需要探索的知识点

CompletableFuture

ConcurentSkipListMap

# 线程的基本概念

之前的硬件，只有一个CPU

之前的OS，只运行一个进程

随着多核CPU的出现，人们开始追求对CPU效率的极致压榨

多线程的程序随之诞生，但随之诞生的，也是非常难以应对的各种并发bug

## 进程 线程

1. 什么是进程：资源分配的基本单位（静态概念）

2. 什么是线程：资源调度的基本单位（动态概念）
   通俗说：作为一个进程里面最小的执行单元它就叫一个线程，用简单的话讲一个程序里不同的执行路径就叫做一个线程

   main方法开启的线程是主线程

   多个线程共享进程的资源

3. 什么是纤程/携程

   <img src=".\image\image-20211227220222686.png" alt="image-20211227220222686" style="zoom:67%;" align="left" />

   

   #### 计算机的组成

   ![image-20211227220518258](.\image\image-20211227220518258.png)

#### 工作线程数（线程池中线程数量）设多少合适?  

**有工具可以计算** 

![image-20211228200743224](.\image\image-20211228200743224.png)



## 为什么要写多线程程序

为了压榨CPU，提高资源利用率

# 启动线程的5种方法

1. new MyThread().start()
2. new Thread(r).start()
3. new Thread(lamda).start()
4. ThreadPool
5. Future Callable and FutureTask

# 常见线程方法

> **sleep()** : 意思就是睡眠，当前线程暂停一段时间让给别的线程去运行。Sleep是怎么复活的？由你的睡眠时间而定，等睡眠到规定的时间自动复活
>
>  **yield()**  : 就是当前线程正在执行的时候停止下来进入等待队列（就绪状态，CPU依然有可能把这个线程拿出来运行），回到等待队列里在系统的调度算法里头呢还是依然有可能把你刚回去的这个线程拿回来继续执行，当然，更大的可能性是把原来等待的那些拿出一个来执行，所以yield的意思是我让出一下CPU，后面你们能不能抢到那我不管
>
>  **join() **: 意思就是在自己当前线程加入你调用Join的线程（），本线程等待。等调用的线程运行完了，自己再去执行。t1和t2两个线程，在t1的某个点上调用了t2.join,它会跑到t2去运行，t1等待t2运行完毕继续t1运行（自己join自己没有意义）
>
> **Daemon()** :守护线程,守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。main() 属于非守护线程。
>
> 

# 线程的状态

**JAVA的6中线程状态:**

1. NEW ：                    线程刚刚创建，还没有启动
2. RUNNABLE ：         可运行状态，由线程调度器可以安排执行
   * 包括READY和RUNNING两种细分状态
3. WAITING：              等待被唤醒
4. TIMED WAITING： 隔一段时间后自动唤醒
5. BLOCKED：            被阻塞，正在等待锁
6. TERMINATED：      线程结束

**如下图：**

![线程状态图](.\image\线程状态图.png)

测试代码

> com.lv.multithread.MyThreadState

# 线程的打断(interrupt)

> 案例 com.lv.multithread.InterruptThread


### interrupt相关的三个方法：

```java
//Thread.java  
public void interrupt()            //t.interrupt() 打断t线程（设置t线程某给标志位f=true，并不是打断线程的运行）
public boolean isInterrupted()     //t.isInterrupted() 查询打断标志位是否被设置（是不是曾经被打断过）
public static boolean interrupted()//Thread.interrupted() 查看“当前”线程是否被打断，如果被打断，恢复标志位
```

### interrupt线程中断总结

> - InterruptedException 会让中断标志位复位
>
> - interrupt()不能打断正在竞争锁(synchronized)的线程，但是可以打断已经竞争到锁的现场
> - 如果想打断正在竞争锁的线程，使用ReentrantLock的lockInterruptibly()
>
> - sleep() wait() join()  方法调用时设置中断信号会打断





# 优雅的结束线程

1. 自然结束（能自然结束就尽量自然结束）

2. stop() 和suspend() resume()

   1. 不建议使用stop，容易产生数据不一致的问题,不管线程是什么状态，直接干掉；但是干掉时会把持有的所有锁全部释放,导致数据不一致
   2. suspend()线程暂停 resume() 重启线程 ，也不建议使用，如果线程暂停会持续持有锁，如果忘记重启线程，会导致死锁。

3. volatile标志
   1. 不适合某些场景（比如还没有同步的时候，线程做了阻塞操作，没有办法循环回去）
   2. 打断时间也不是特别精确，比如一个阻塞容器，容量为5的时候结束生产者，
      但是，由于volatile同步线程标志位的时间控制不是很精确，有可能生产者还继续生产一段儿时间

4. interrupt() and isInterrupted（比较优雅）

   1. 缺点是时间控制不精确 ，如在某个点精确停止，不一定能做到

   



# 并发程序的特性

程序是什么？--> QQ.exe PowerPoint.exe

进程是什么？--> 程序启动 进入内存 资源分配的基本单位

线程是什么？--> 程序执行的基本单位

程序如何开始运行？--> CPU 读指令 - PC（存储指令地址） ，读数据 Register ，计算， 回写， -> 下一条

线程如何进行调度？--> linux 线程调度器（OS)操作系统

线程切换的概念是什么？--> Context Switch CPU保存现场 执行新线程，恢复现场，继续执行原线程这样的一个过程

## 线程的底层知识（可见性 有序性 原子性）

1. 线程的执行
2. 线程的调度（Context Switch）
   1. 一个核同一时刻，只能运行一个线程

**面试题：**

1. 是不是线程数越多，效率就越高？
2. 单个CPU设定多线程是否有意义？

## 可见性

### 线程间的可见性

**MESI**

多线程提高效率，本地缓存数据，造成数据修改不可见，

要想保证可见，要么触发同步指令，要么加上volatile，被修饰的内存，只要有修改，马上同步涉及到的每个线程

### 用volatile保障可见性

```java
/**
 * volatile 关键字，使一个变量在多个线程间可见
 * A B线程都用到一个变量，java默认是A线程中保留一份copy，这样如果B线程修改了该变量，则A线程未必知道
 * 使用volatile关键字，会让所有线程都会读到变量的修改值
 * 
 * 在下面的代码中，running是存在于堆内存的t对象中
 * 当线程t1开始运行的时候，会把running值从内存中读到t1线程的工作区，在运行过程中直接使用这个copy，并不会每次都去
 * 读取堆内存，这样，当主线程修改running的值之后，t1线程感知不到，所以不会停止运行
 * 
 * 使用volatile，将会强制所有线程都去堆内存中读取running的值
 * 
 * volatile并不能保证多个线程共同修改running变量时所带来的不一致问题，也就是说volatile不能替代synchronized
 *
 * @author mashibing
 */
package com.mashibing.juc.c_001_00_Visibility;

import com.mashibing.util.SleepHelper;

public class T01_HelloVolatile {
    private static volatile boolean running = true;

    private static void m() {
        System.out.println("m start");
        while (running) {
            //System.out.println("hello");
        }
        System.out.println("m end!");
    }

    public static void main(String[] args) {

        new Thread(T01_HelloVolatile::m, "t1").start();

        SleepHelper.sleepSeconds(1);

        running = false;
    }
}



```

![image-20220102175822243](.\image\image-20220102175822243.png)



### 缓存行对齐

* 缓存行对齐
  缓存行64个字节是CPU同步的基本单位，缓存行隔离会比伪共享效率要高,因为没有内核缓存间相互通知或同步的操作
  
  volatile  与缓存行的概念没有关系
  
  Disruptor：一个著名的同步队列框架`https://tech.meituan.com/2016/11/18/disruptor.html`
  
* 认识缓存行对齐的编程技巧

  ```java
  package com.mashibing.juc.c_001_02_FalseSharing;
  
  import java.util.concurrent.CountDownLatch;
  
  public class T01_CacheLinePadding {
      public static long COUNT = 10_0000_0000L;
  
      private static class T {
          private long p1, p2, p3, p4, p5, p6, p7; //只为填充字节，使多个x缓存行不在同一行
          public long x = 0L;
          private long p9, p10, p11, p12, p13, p14, p15;
      }
  
      public static T[] arr = new T[2];
  
      static {
          arr[0] = new T();
          arr[1] = new T();
      }
  
      public static void main(String[] args) throws Exception {
          CountDownLatch latch = new CountDownLatch(2);
  
          Thread t1 = new Thread(()->{
              for (long i = 0; i < COUNT; i++) {
                  arr[0].x = i;
              }
  
              latch.countDown();
          });
  
          Thread t2 = new Thread(()->{
              for (long i = 0; i < COUNT; i++) {
                  arr[1].x = i;
              }
  
              latch.countDown();
          });
  
          final long start = System.nanoTime();
          t1.start();
          t2.start();
          latch.await();
          System.out.println((System.nanoTime() - start)/100_0000);
      }
  }
  
  ```

  

* **需要注意，JDK8引入了@sun.misc.Contended注解，来保证缓存行隔离效果**
  要使用此注解，必须去掉限制参数：-XX:-RestrictContended，只有JDK1.8有，1.9后又去掉了

  ```java
  package com.mashibing.juc.c_001_02_FalseSharing;
  
  
  import sun.misc.Contended;
  //注意：运行这个小程序的时候，需要加参数：-XX:-RestrictContended
  import java.util.concurrent.CountDownLatch;
  
  public class T05_Contended {
      public static long COUNT = 10_0000_0000L;
  
  
      private static class T {
          @Contended  //只有1.8起作用 , 保证x位于单独一行中
          public long x = 0L;
      }
  
      public static T[] arr = new T[2];
  
      static {
          arr[0] = new T();
          arr[1] = new T();
      }
  
      public static void main(String[] args) throws Exception {
          CountDownLatch latch = new CountDownLatch(2);
  
          Thread t1 = new Thread(()->{
              for (long i = 0; i < COUNT; i++) {
                  arr[0].x = i;
              }
  
              latch.countDown();
          });
  
          Thread t2 = new Thread(()->{
              for (long i = 0; i < COUNT; i++) {
                  arr[1].x = i;
              }
  
              latch.countDown();
          });
  
          final long start = System.nanoTime();
          t1.start();
          t2.start();
          latch.await();
          System.out.println((System.nanoTime() - start)/100_0000);
      }
  }
  
  ```

  

## 有序性

### CPU的乱序执行

Disorder这个程序，证明乱序执行的确存在



<img src=".\image\image-20220102195905831.png" alt="image-20220102195905831" style="zoom:100%;" align="left" />

<img src=".\image\image-20220102195612602.png" alt="image-20220102195612602 " style="zoom:80%;" align="left" />





**为什么会乱序**？主要是为了提高效率,但如果有强依赖关系，指令2依赖指令1则不存在乱序

![image-20220102200242318](.\image\image-20220102200242318.png)

### 乱序存在的条件

1. ​	as-if-serial：翻译：看上去像是序列化（单线程）
2. ​	不影响单线程的最终一致性

### 线程的as-if-serial

单个线程，两条语句，未必是按顺序执行

单线程的重排序，必须保证最终一致性

### 会产生的后果

多线程会产生不希望看到的结果

### 哪些指令可以互换顺序

hanppens-before原则（JVM规定重排序必须遵守的规则）

**书JLS17.4.5节 （不需要记住）了解一下**

•程序次序规则：同一个线程内，按照代码出现的顺序，前面的代码先行于后面的代码，准确的说是控制流顺序，因为要考虑到分支和循环结构。

•管程锁定规则：一个unlock操作先行发生于后面（时间上）对同一个锁的lock操作。

•**volatile变量规则：对一个volatile变量的写操作先行发生于后面（时间上）对这个变量的读操作。** 

•线程启动规则：Thread的start( )方法先行发生于这个线程的每一个操作。 

•线程终止规则：线程的所有操作都先行于此线程的终止检测。可以通过Thread.join( )方法结束、Thread.isAlive( )的返回值等手段检测线程的终止。 

•线程中断规则：对线程interrupt( )方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupt( )方法检测线程是否中断 

•对象终结规则：一个对象的初始化完成先行于发生它的finalize()方法的开始。

•传递性：如果操作A先行于操作B，操作B先行于操作C，那么操作A先行于操作C



### 使用内存屏障阻止乱序执行

内存屏障是特殊指令：看到这种指令，前面的必须执行完，后面的才能执行

intel : lfence sfence mfence(CPU特有指令)

### JVM中的内存屏障

所有实现JVM规范的虚拟机，必须实现四个屏障

![image-20220102205705107](.\image\image-20220102205705107.png)

### volatile的底层实现

volatile修饰的内存，不可以重排序，对volatile修饰变量的读写访问，都不可以换顺序



## 原子性

### 线程的原子性

从一个简单的小程序谈起：

```java
package com.mashibing.juc.c_001_sync_basics;

import java.util.concurrent.CountDownLatch;

public class T00_IPlusPlus {
    private static long n = 0L;

    public static void main(String[] args) throws Exception {

        Thread[] threads = new Thread[100];
        CountDownLatch latch = new CountDownLatch(threads.length);

        for (int i = 0; i < threads.length; i++) {
            threads[i] = new Thread(() -> {
                for (int j = 0; j < 10000; j++) {
                    //synchronized (T00_IPlusPlus.class) {
                    n++;
                    //}
                }
                latch.countDown();
            });
        }

        for (Thread t : threads) {
            t.start();
        }

        latch.await();

        System.out.println(n);

    }
}
```

**一些基本概念**



race condition => 竞争条件 ， 指的是多个线程访问共享数据的时候产生竞争

数据的不一致（unconsistency)，并发访问之下产生的不期望出现的结果

如何保障数据一致呢？--> 线程同步（线程执行的顺序安排好），

monitor （管程） ---> 锁

critical section -> 临界区

如果临界区执行时间长，语句多，叫做 锁的粒度比较粗，反之，就是锁的粒度比较细



具体： 保障操作的原子性（Atomicity)

1. 悲观的认为这个操作会被别的线程打断（悲观锁）synchronized（上一个小程序）

2. 乐观的认为这个做不会被别的线程打断（乐观锁 自旋锁 无锁）cas操作
   CAS = Compare And Set/Swap/Exchange

   ​	解决ABA问题加版本标识
   
   ![image-20220103210747737](.\image\image-20220103210747737.png)
   
   ```java
   /**
    * 解决同样的问题的更高效的方法，使用AtomXXX类
    * AtomXXX类本身方法都是原子性的，但不能保证多个方法连续调用是原子性的
    * @author mashibing
    */
   package com.mashibing.juc.c_018_00_AtomicXXX;
   
   import java.util.ArrayList;
   import java.util.List;
   import java.util.concurrent.atomic.AtomicInteger;
   
   
   public class T01_AtomicInteger {
   	/*volatile*/ //int count1 = 0;
   	
   	AtomicInteger count = new AtomicInteger(0);
   
   	/* synchronized */void m() {
   		for (int i = 0; i < 10000; i++)
   			//if count1.get() < 1000
   			count.incrementAndGet(); //count1++
   	}
   
   	public static void main(String[] args) {
   		T01_AtomicInteger t = new T01_AtomicInteger();
   
   		List<Thread> threads = new ArrayList<Thread>();
   
   		for (int i = 0; i < 100; i++) {
   			threads.add(new Thread(t::m, "thread-" + i));
   		}
   
   		threads.forEach((o) -> o.start());
   
   		threads.forEach((o) -> {
   			try {
   				o.join();
   			} catch (InterruptedException e) {
   				e.printStackTrace();
   			}
   		});
   
   		System.out.println(t.count);
   
   	}
   
   }
   
   ```
   
   

我们平时所说的"上锁"，一般指的是悲观锁

### 上锁的本质

上锁的本质是把并发编程序列化

```java
package com.mashibing.juc.c_001_sync_basics;

import com.mashibing.util.SleepHelper;

public class T00_01_WhatIsLock {
    private static Object o = new Object();

    public static void main(String[] args) {
        Runnable r = () -> {
            //synchronized (o) { //打开注释试试看，对比结果
                System.out.println(Thread.currentThread().getName() + " start!");
                SleepHelper.sleepSeconds(2);
                System.out.println(Thread.currentThread().getName() + " end!");
            //}
        };

        for (int i = 0; i < 3; i++) {
            new Thread(r).start();
        }
    }
}

```



同时保障可见性

注意序列化并非其他程序一直没机会执行，而是有可能会被调度，但是抢不到锁，又回到Blocked或者Waiting状态（sync锁升级）

一定是锁定同一把锁（抢一个坑位）



```java
package com.mashibing.juc.c_001_sync_basics;

import com.mashibing.util.SleepHelper;

public class T00_02_SingleLockVSMultiLock {
    private static Object o1 = new Object();
    private static Object o2 = new Object();
    private static Object o3 = new Object();

    public static void main(String[] args) {
        Runnable r1 = () -> {
            synchronized (o1) {
                System.out.println(Thread.currentThread().getName() + " start!");
                SleepHelper.sleepSeconds(2);
                System.out.println(Thread.currentThread().getName() + " end!");
            }
        };

        Runnable r2 = () -> {
            synchronized (o2) {
                System.out.println(Thread.currentThread().getName() + " start!");
                SleepHelper.sleepSeconds(2);
                System.out.println(Thread.currentThread().getName() + " end!");
            }
        };

        Runnable r3 = () -> {
            synchronized (o3) {
                System.out.println(Thread.currentThread().getName() + " start!");
                SleepHelper.sleepSeconds(2);
                System.out.println(Thread.currentThread().getName() + " end!");
            }
        };

        new Thread(r1).start();
        new Thread(r2).start();
        new Thread(r3).start();
    }
}

```



### 什么样的语句（指令）具备原子性？

CPU级别汇编，需要查询汇编手册！

Java中的8大原子操作：（了解即可，无需背过）

1. lock：主内存，标识变量为线程独占
2. unlock：主内存，解锁线程独占变量
3. read：主内存，读取内存到线程缓存（工作内存）
4. load：工作内存，read后的值放入线程本地变量副本
5. use：工作内存，传值给执行引擎
6. assign：工作内存，执行引擎结果赋值给线程本地变量
7. store：工作内存，存值到主内存给write备用
8. write：主内存，写变量值

### JVM中的两种锁

重量级锁（经过操作系统的调度）synchronized早期都是这种锁（目前的实现中升级到最后也是这种锁）

轻量级锁（CAS的实现，不经过OS调度）(无锁 - 自旋锁 - 乐观锁)



### CAS的深度剖析

CAS的ABA问题解决方案 - Version

CAS操作本身的原子性保障

AtomicInteger:

```java
public final int incrementAndGet() {
        for (;;) {
            int current = get();
            int next = current + 1;
            if (compareAndSet(current, next))
                return next;
        }
    }

public final boolean compareAndSet(int expect, int update) {
        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
    }
```

Unsafe:

```java
public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);
```

运用：

```java
package com.mashibing.jol;

import sun.misc.Unsafe;

import java.lang.reflect.Field;

public class T02_TestUnsafe {

    int i = 0;
    private static T02_TestUnsafe t = new T02_TestUnsafe();

    public static void main(String[] args) throws Exception {
        //Unsafe unsafe = Unsafe.getUnsafe();

        Field unsafeField = Unsafe.class.getDeclaredFields()[0];
        unsafeField.setAccessible(true);
        Unsafe unsafe = (Unsafe) unsafeField.get(null);

        Field f = T02_TestUnsafe.class.getDeclaredField("i");
        long offset = unsafe.objectFieldOffset(f);
        System.out.println(offset);

        boolean success = unsafe.compareAndSwapInt(t, offset, 0, 1);
        System.out.println(success);
        System.out.println(t.i);
        //unsafe.compareAndSwapInt()
    }
}
```

jdk8u: unsafe.cpp:

cmpxchg = compare and exchange set swap

```c++
UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))
  UnsafeWrapper("Unsafe_CompareAndSwapInt");
  oop p = JNIHandles::resolve(obj);
  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);
  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;
UNSAFE_END
```

jdk8u: atomic_linux_x86.inline.hpp **93行**

is_MP = Multi Processors  

```c++
inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value) {
  int mp = os::is_MP();
  __asm__ volatile (LOCK_IF_MP(%4) "cmpxchgl %1,(%3)"
                    : "=a" (exchange_value)
                    : "r" (exchange_value), "a" (compare_value), "r" (dest), "r" (mp)
                    : "cc", "memory");
  return exchange_value;
}
```

jdk8u: os.hpp is_MP()

```c++
  static inline bool is_MP() {
    // During bootstrap if _processor_count is not yet initialized
    // we claim to be MP as that is safest. If any platform has a
    // stub generator that might be triggered in this phase and for
    // which being declared MP when in fact not, is a problem - then
    // the bootstrap routine for the stub generator needs to check
    // the processor count directly and leave the bootstrap routine
    // in place until called after initialization has ocurred.
    return (_processor_count != 1) || AssumeMP;
  }
```

jdk8u: atomic_linux_x86.inline.hpp

```c++
#define LOCK_IF_MP(mp) "cmp $0, " #mp "; je 1f; lock; 1: "
```

最终实现：

cmpxchg = cas修改变量值

```assembly
lock cmpxchg 指令
```

硬件：

lock指令在执行的时候视情况采用缓存锁或者总线锁



#### 两种锁的效率

不同的场景：

临界区执行时间比较长 ， 等的人很多 -> 重量级

时间短，等的人少 -> 自旋锁

### synchronized如何保障可见性

![image-20201019185528202](.\image\synchronized保障可见性.png)

# synchronized详解

## synchronized加锁的三种方式

> 1. 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁
>2. 静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁
>3. 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

## synchronized的字节码指令

 这两个指令，本质上都是对一个对象的监视器(monitor)进行获取，这个过程是排他的，也就是说同一时刻只能有
一个线程获取到由synchronized所保护对象的监视器，jvm需要保证每个monitorenter都有一个monitorexit对应。

![image-20220112210302331](.\image\image-20220112210302331.png)

**Monitorenter指令**

 会让对象在执行时，使其锁计数器加1或者减1。每一个对象在同一时间只与一个monitor(锁)
相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一：

- monitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待
- 如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加
- 这把锁已经被别的线程获取了，等待锁释放

**monitorexit指令**：


释放对于monitor的所有权，释放过程很简单，就是讲monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。

下图表现了对象，对象监视器，同步队列以及执行线程状态之间的关系：

<img src=".\image\java-thread-x-key-schronized-2.png" alt="img" align="left" style="zoom:100%;" />

 该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。

## Monitor

1.Monitor是一种用来实现同步的工具

2.与每个java对象相关联，所有的 Java 对象是天生携带 monitor

3.Monitor是实现Sychronized(内置锁)的基础

```c++
ObjectMonitor() {
    _count        = 0; //用来记录该对象被线程获取锁的次数
    _waiters      = 0;
    _recursions   = 0; //锁的重入次数
    _owner        = NULL; //指向持有ObjectMonitor对象的线程 
    _WaitSet      = NULL; //处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _EntryList    = NULL ; //处于等待锁block状态的线程，会被加入到该列表
}
```

## synchronized锁重入性原理

>  synchronized 是可重入锁，重入次数必须记录，因为要解锁几次，必须对应

锁记录

- 偏向锁与轻量级锁记录在线程栈中，每重入一次LockRecord+1
- 重量级锁的信息看Monitor，每个锁对象都有一个monitor,当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。

## synchronized可见性原理

> happens-before 规则

## 用户态与内核态

 JDK早期的时候，synchronized叫做重量级锁，JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex
Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；

参考： https://www.cnblogs.com/maxigang/p/9041080.html

### markword

 8个字节

> 工具：JOL=java Object Layout

```xml
<dependencies>
<!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core -->
    <dependency>
        <groupId>org.openjdk.jol</groupId>
        <artifactId>jol-core</artifactId>
        <version>0.9</version>
    </dependency>
</dependencies>
```

使用方法

```java
public class Synchroized {
    public static void main(String[] args) {
        Object o=new Object();
        System.out.println(ClassLayout.parseInstance(o).toPrintable());

        synchronized (o){
            System.out.println(ClassLayout.parseInstance(o).toPrintable());
        }
    }
}
```

输出结果

1、前面两行为markword的信息 2、最后一行（loss due to the next object alignment）是为补位，只为了这个对象字节数能够整除8 3、markword中记录着锁，GC、HashCode等

4、value的信息是通过小端展示，所以第一字节是最后一个

> 小端大端详解：https://blog.csdn.net/shikaiwencn/article/details/47183921

```

java.lang.Object object internals:
 OFFSET  SIZE   TYPE DESCRIPTION                               VALUE
      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)
      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4        (object header)                           e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)
     12     4        (loss due to the next object alignment)
Instance size: 16 bytes
Space losses: 0 bytes internal + 4 bytes external = 4 bytes total
=============================================================================================================================
java.lang.Object object internals:
 OFFSET  SIZE   TYPE DESCRIPTION                               VALUE
      0     4        (object header)                           48 f3 d5 02 (01001000 11110011 11010101 00000010) (47575880)
      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4        (object header)                           e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)
     12     4        (loss due to the next object alignment)
Instance size: 16 bytes
Space losses: 0 bytes internal + 4 bytes external = 4 bytes total

```

#### markword信息详解（64位）

>  markword最后两位是锁标志位，可以通过此信息确定是什么锁，偏向锁需要最后三位来确认
>
>  hashcode=identity hashcode

<img src=".\image\image-20220112203536880.png" alt="image-20220112203536880" style="zoom:150%;" />

## synchronized锁升级的过程

![image-20220112203901041](.\image\image-20220112203901041.png)

- 普通对象 + synchronized 形成偏向锁

- 轻量级锁=自旋锁=无锁

- 偏向锁和轻量级锁 是用户空间，重量级锁

- 偏向锁启动：偏向锁已启动的情况,创建新对象是101，此时称为匿名偏向，添加synchronized后，变成偏向锁

- 偏向锁未启动：偏向锁启动的情况（jvm默认延迟4秒启动）,创建新对象是001

- 锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的)

  

#### 自旋锁

> 引入背景：大家都知道，在没有加入锁优化时，Synchronized是一个非常“胖大”的家伙。在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁由来的原因。

自旋锁早在JDK1.4 中就引入了，只是当时默认时关闭的。在JDK 1.6后默认为开启状态。自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源)。因此自旋等待的时间必须要有一定的限度，如果自选超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了，在JDK定义中，自旋锁默认的自旋次数为10次，用户可以使用参数`-XX:PreBlockSpin`来更改。

可是现在又出现了一个问题：如果线程锁在线程自旋刚结束就释放掉了锁，那么是不是有点得不偿失。所以这时候我们需要更加聪明的锁来实现更加灵活的自旋。来提高并发的性能。(这里则需要自适应自旋锁！)

#### 自适应自旋锁

 在JDK 1.6中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋 时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，JVM对程序的锁的状态预测会越来越准确，JVM也会越来越聪明。

#### 轻量级锁

在JDK 1.6之后引入的轻量级锁，需要注意的是轻量级锁并不是替代重量级锁的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。它可以减少重量级锁对线程的阻塞带来地线程开销。从而提高并发性能。

如果要理解轻量级锁，那么必须先要了解HotSpot虚拟机中对象头地内存布局。上面介绍Java对象头也详细介绍过。在对象头中(`Object Header`)存在两部分。第一部分用于存储对象自身的运行时数据，`HashCode`、`GC Age`、`锁标记位`、`是否为偏向锁`。等。一般为32位或者64位(视操作系统位数定)。官方称之为`Mark Word`，它是实现轻量级锁和偏向锁的关键。 另外一部分存储的是指向方法区对象类型数据的指针(`Klass Point`)，如果对象是数组的话，还会有一个额外的部分用于存储数据的长度。

#### 轻量级锁加锁

在线程执行同步块之前，JVM会先在当前线程的栈帧中创建一个名为锁记录(`Lock Record`)的空间，用于存储锁对象目前的`Mark Word`的拷贝(JVM会将对象头中的`Mark Word`拷贝到锁记录中，官方称为`Displaced Mark Ward`)这个时候线程堆栈与对象头的状态如图：

<img src=".\image\java-thread-x-key-schronized-5.png" alt="img" align="left" style="zoom:120%;" />

如上图所示：如果当前对象没有被锁定，那么锁标志位位01状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录`Lock Record`的空间用于存储锁对象目前的`Mark Word`的拷贝。

 然后，虚拟机使用CAS操作将标记字段Mark Word拷贝到锁记录中，并且将`Mark Word`更新为指向`Lock Record`的指针。如果更新成功了，那么这个线程就有用了该对象的锁，并且对象Mark Word的锁标志位更新为(`Mark Word`中最后的2bit)00，即表示此对象处于轻量级锁定状态，如图：

<img src=".\image\java-thread-x-key-schronized-6.png" alt="img" align="left" style="zoom:120%;" />

 如果这个更新操作失败，JVM会检查当前的`Mark Word`中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀位重量级锁，没有获得锁的线程会被阻塞。此时，锁的标志位为`10.Mark Word`中存储的时指向重量级锁的指针。

 轻量级解锁时，会使用原子的CAS操作将`Displaced Mark Word`替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系。锁就会膨胀成重量级锁。两个线程同时争夺锁，导致锁膨胀的流程图如下：

<img src=".\image\java-thread-x-key-schronized-7.png" alt="img" align="left" style="zoom:120%;" />

####  偏向锁

> 引入背景：在大多实际环境下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，那么这样看上去，多次的获取锁和释放锁带来了很多不必要的性能开销和上下文切换。

 为了解决这一问题，HotSpot的作者在Java SE 1.6 中对Synchronized进行了优化，引入了偏向锁。当一个线程访问同步快并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和推出同步块时不需要进行CAS操作来加锁和解锁。只需要简单地测试一下对象头的`Mark Word`里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。

<img src=".\image\java-thread-x-key-schronized-8.png" alt="img" align="left" style="zoom:120%;" />

#### 偏向锁的撤销

 偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。

<img src=".\image\java-thread-x-key-schronized-9.png" align="left" alt="img" style="zoom:120%;" />

#### 重量级锁：

 通过对象内部的监视器(monitor)实现，其中monitor的本质是依赖于底层操作系统的Mutex Lock实
现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。线程竞争不使用自旋，不会消耗CPU。但是线程会进入阻塞等待被其他线程被唤醒，响应时间缓慢。

#### 锁消除与锁优化

https://blog.csdn.net/qq_26222859/article/details/80546917

#### 锁的优缺点对比

| 锁       | 优点                                                         | 缺点                                                         | 使用场景                           |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------- |
| 偏向锁   | 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗               | 适用于只有一个线程访问同步快的场景 |
| 轻量级锁 | 竞争的线程不会阻塞，提高了响应速度                           | 如线程成始终得不到锁竞争的线程，使用自旋会消耗CPU性能        | 追求响应时间，同步快执行速度非常快 |
| 重量级锁 | 线程竞争不适用自旋，不会消耗CPU                              | 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 | 追求吞吐量，同步快执行速度较长     |





### 为什么有自旋锁还需要重量级锁

> 自旋是消耗CPU资源的，如果锁的时间长，或者自旋锁线程多，CPU会被大量消耗
>
> 而重量级锁是有等待队列，不需要消耗CPU资源的，只需要等待系统进行处理

### 偏向锁是否一定比自旋锁效率高

> 不一定，在明确知道会有多线程竟争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用轻量锁
>
> jvm启动过程中，会有很多线程竟争锁，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作， 效率很低
>
> 默认情况下偏向锁的时延是4秒，通过以下参数可以设置时间

> -XX:BiasedLockingstartupDelay=0



> 参考：https://blog.csdn.net/baidu_38083619/article/details/82527461

# volatile详解

> 可以实现可见性、有序性，但是无法保证是线程安全的
>

### volatile 可见性实现

> volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现:， JVM的内存屏障是基于硬件OS层面的内存屏障实现的

- 内存屏障，又称内存栅栏，是一个 CPU 指令。
- 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和
  CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。

写一段简单的 Java 代码，声明一个 volatile 变量，并赋值。

```java
public class Test {
    private volatile int a;
    public void update() {
        a = 1;
    }
    public static void main(String[] args) {
        Test test = new Test();
        test.update();
    }
}
  
    
```

通过 hsdis 和 jitwatch 工具可以得到编译后的汇编代码:

```bash
......
  0x0000000002951563: and    $0xffffffffffffff87,%rdi
  0x0000000002951567: je     0x00000000029515f8
  0x000000000295156d: test   $0x7,%rdi
  0x0000000002951574: jne    0x00000000029515bd
  0x0000000002951576: test   $0x300,%rdi
  0x000000000295157d: jne    0x000000000295159c
  0x000000000295157f: and    $0x37f,%rax
  0x0000000002951586: mov    %rax,%rdi
  0x0000000002951589: or     %r15,%rdi
  0x000000000295158c: lock cmpxchg %rdi,(%rdx)  //在 volatile 修饰的共享变量进行写操作的时候会多出 lock 前缀的指令
  0x0000000002951591: jne    0x0000000002951a15
  0x0000000002951597: jmpq   0x00000000029515f8
  0x000000000295159c: mov    0x8(%rdx),%edi
  0x000000000295159f: shl    $0x3,%rdi
  0x00000000029515a3: mov    0xa8(%rdi),%rdi
  0x00000000029515aa: or     %r15,%rdi
......
  
```

lock 前缀的指令在多核处理器下会引发两件事情:

- 将当前处理器缓存行的数据写回到系统内存。
- 写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。

为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2 或其他)后再进行操作，但操作完不知道何时会写到内存。如果对声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条
lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。为了保证各个处理器的缓存是一致的，实现了缓存一致性协议(MESI)
，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。所有多核处理器下还会完成：当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。volatile
变量通过这样的机制就使得每个线程都能获得该变量的最新值。

#### lock 指令的作用

1. 锁总线，其它CPU对内存的读写请求都会被阻塞，直到锁释放，不过实际后来的处理器都采用锁缓存替代锁总线，因为锁总线的开销比较大，锁总线期间其他CPU没法访问内存
2. lock后的写操作会回写已修改的数据，同时让其它CPU相关缓存行失效，从而重新从主存中加载最新的数据
3. 不是内存屏障却能完成类似内存屏障的功能，阻止屏障两边的指令重排序

#### 缓存一致性

缓存是分段(line)的，一个段对应一块存储空间，称之为缓存行，它是 CPU 缓存中可分配的最小存储单元，大小 32 字节、64 字节、128 字节不等，这与 CPU 架构有关，通常来说是 64 字节。
LOCK#因为锁总线效率太低，因此使用了多组缓存。 为了使其行为看起来如同一组缓存那样。因而设计了 缓存一致性协议。 缓存一致性协议有多种，但是日常处理的大多数计算机设备都属于 " 嗅探(snooping)"
协议。所有内存的传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线。 缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁(同一个指令周期中，只有一个 CPU 缓存可以读写内存)。
CPU缓存不仅仅在做内存传输的时候才与总线打交道，而是不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。
当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。只要某个处理器写内存，其它处理器马上知道这块内存在它们的缓存段中已经失效。

###### MESI

> MESI是目前最主流的缓存一致性协议

在MESI协议中，每个缓存行有4个状态，可用2个bit表示，它们分别是：

<img src=".\image\20180518163748812" alt="img" style="zoom:100%;" align="left"/>


这里的I、S和M状态已经有了对应的概念：失效/未载入、干净以及脏的缓存段。所以这里新的知识点只有E状态，代表独占式访问，这个状态解决了”在我们开始修改某块内存之前，我们需要告诉其它处理器”这一问题：只有当缓存行处于E或者M状态时，处理器才能去写它，也就是说只有在这两种状态下，处理器是独占这个缓存行的。当处理器想写某个缓存行时，如果它没有独占权，它必须先发送一条”我要独占权”的请求给总线，这会通知其它处理器把它们拥有的同一缓存段的拷贝失效（如果有）。只有在获得独占权后，处理器才能开始修改数据—-并且此时这个处理器知道，这个缓存行只有一份拷贝，在我自己的缓存里，所以不会有任何冲突。反之，如果有其它处理器想读取这个缓存行（马上能知道，因为一直在嗅探总线），独占或已修改的缓存行必须先回到”共享”状态。如果是已修改的缓存行，那么还要先把内容回写到内存中。

### volatile不能保证线程安全(原子性)

在以下的例子中，多个线程同时读到T的值，此时各个线程缓存中的值为0，假如线程1进行t+1操作，但是并未对t的变量进行赋值，但是已经完成自增操作，此事线程2再进行自增还是按照0的初始值进行自增，此时就出现的线程安全问题。

```java
public class Volatile_ThreadSafe {
    public static volatile int t = 0;

    public static void main(String[] args) {

        Thread[] threads = new Thread[10];
        for (int i = 0; i < 10; i++) {
            //每个线程对t进行1000次加1的操作
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int j = 0; j < 1000; j++) {
                        t++; // 或者t=t+1
                    }
                }
            });
            threads[i].start();
        }

        //等待所有累加线程都结束
        while (Thread.activeCount() > 1) {
            Thread.yield();
        }

        //打印t的值
        System.out.println(t);
    }
}
```

## volatile 有序性实现

#### 乱序的原因

> CPU为了提高指令执行效率，会在一条指令执行过程中（比如去内存读数据（慢100倍）），去同时执行另一条指令，前提是，两条指令没有依赖关系
>
> CPU缓存的单元的处理时长看-jvm.md的Java内存模型

#### happens-before规则详解

> https://segmentfault.com/a/1190000011458941

#### volatile 的 happens-before 关系

happens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。就是在读之前必须写入完成

```java
//假设线程A执行writer方法，线程B执行reader方法
class VolatileExample {
    int a = 0;
    volatile boolean flag = false;

    public void writer() {
        a = 1;              // 1 线程A修改共享变量
        flag = true;        // 2 线程A写volatile变量
    }

    public void reader() {
        if (flag) {         // 3 线程B读同一个volatile变量
            int i = a;          // 4 线程B读共享变量
        ……
        }
    }
}


```

根据 happens-before 规则，上面过程会建立 3 类 happens-before 关系。

- 根据程序次序规则：1 happens-before 2 且 3 happens-before 4。
- 根据 volatile 规则：2 happens-before 3。
- 根据 happens-before 的传递性规则：1 happens-before 4。

<img src=".\image\java-thread-x-key-volatile-1.png" alt="img"  align="left" style="zoom:100%;" />

因为以上规则，当线程 A 将 volatile 变量 flag 更改为 true 后，线程 B 能够迅速感知。

#### volatile 禁止重排序

为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。

Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。

#### 硬件内存屏障 X86架构

> sfence: store| 在sfence指令前的写操作当必须在sfence指令后的写操作前完成。
>
> lfence：load | 在lfence指令前的读操作当必须在lfence指令后的读操作前完成。
>
> mfence：modify/mix | 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。

> 原子指令，如x86上的”lock …” 指令是一个Full Barrier，执行时会锁住内存子系统来确保执行顺序，甚至跨多个CPU。Software Locks通常使用了内存屏障或原子指令来实现变量可见性和保持程序顺序

#### JMM内存屏障

JMM 会针对编译器制定 volatile 重排序规则表。

<img src=".\image\java-thread-x-key-volatile-2.png" align="left" alt="img" style="zoom:100%;" />

" NO " 表示禁止重排序。

为了实现 volatile 内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。

对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM 采取了保守的策略。

- 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。
- 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。
- 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。
- 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。

volatile 写是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。

| 内存屏障        | 说明                                                        |
| --------------- | ----------------------------------------------------------- |
| StoreStore 屏障 | 禁止上面的普通写和下面的 volatile 写重排序。                |
| StoreLoad 屏障  | 防止上面的 volatile 写与下面可能有的 volatile 读/写重排序。 |
| LoadLoad 屏障   | 禁止下面所有的普通读操作和上面的 volatile 读重排序。        |
| LoadStore 屏障  | 禁止下面所有的普通写操作和上面的 volatile 读重排序。        |

<img src=".\image\java-thread-x-key-volatile-3.png" align="left" alt="img" style="zoom:100%;" />

<img src=".\image\java-thread-x-key-volatile-4.png" align="left"  alt="img" style="zoom:100%;" />



> 参考地址：
>
> lock指令与缓存一致性    https://blog.csdn.net/qq_26222859/article/details/52235930
>
>  cpu缓存与合并写： https://www.cnblogs.com/liushaodong/p/4777308.html
>
> MESIX缓存行协议：https://www.cnblogs.com/z00377750/p/9180644.html



# JUC

> ​	java包路径 java.util.concurrent 的简称

## CAS

​		CAS的全称为Compare-And-Swap，直译就是对比交换。是一条CPU的原子指令，其作用是让CPU先进行比较两个值是否相等，然后原子地更新某个位置的值，经过调查发现，其实现方式是基于硬件平台的汇编指令，就是说CAS是靠硬件实现的，JVM只是封装了汇编调用，那些AtomicInteger类便是使用了这些封装后的接口。  简单解释：CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较下在旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。

CAS操作是原子性的，所以多线程并发使用CAS更新数据时，可以不使用锁。JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。

相信sql大家都熟悉，类似sql中的条件更新一样：update set id=3 from table where id=2。因为单条sql执行具有原子性，如果有多个线程同时执行此sql语句，只有一条能更新成功。

### 		ABA

​	因为CAS需要在操作值的时候，检查值有没有发生变化，比如没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时则会发现它的值没有发生变化，但是实际上却变化了。

ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A。

从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

### 循环时间长开销大

​	自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行命令(de-pipeline)，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突(Memory Order Violation)而引起CPU流水线被清空(CPU Pipeline Flush)，从而提高CPU的执行效率。

### 只能保证一个共享变量的原子操作

​	当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i = 2，j = a，合并一下ij = 2a，然后用CAS来操作ij。

从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。



## unsafe 

> ​	上文我们了解到Java原子类是通过UnSafe类实现的，这节主要分析下UnSafe类。UnSafe类在J.U.C中CAS操作有很广泛的应用。

​	Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。

这个类尽管里面的方法都是 public 的，但是并没有办法使用它们，JDK API 文档也没有提供任何关于这个类的方法的解释。总而言之，对于 Unsafe 类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然 JDK 库里面的类是可以随意使用的。

先来看下这张图，对UnSafe类总体功能：

![img](.\image\java-thread-x-atomicinteger-unsafe.png)

## lock





## 同步容器

### BlockingQueue

#### BlockingQueue整体继承关系

![img](D:\system\custom_code\demo-jdk\src\resources\note\多线程\image\企业微信截图_16450892802678.png)



####  BlockingQueue

BlockingQueue 通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。下图是对这个原理的阐述:

<img src="D:\system\custom_code\demo-jdk\src\resources\note\多线程\image\java-thread-x-blocking-queue-1.png" align="left" alt="img" style="zoom:100%;" />

一个线程往里边放，另外一个线程从里边取的一个 BlockingQueue。

一个线程将会持续生产新对象并将其插入到队列之中，直到队列达到它所能容纳的临界点。也就是说，它是有限的。如果该阻塞队列到达了其临界点，负责生产的线程将会在往里边插入新对象时发生阻塞。它会一直处于阻塞之中，直到负责消费的线程从队列中拿走一个对象。 负责消费的线程将会一直从该阻塞队列中拿出对象。如果消费线程尝试去从一个空的队列中提取对象的话，这个消费线程将会处于阻塞之中，直到一个生产线程把一个对象丢进队列。



##### BlockingQueue 的方法

BlockingQueue 具有 4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下:

|      | 抛异常     | 特定值   | 阻塞    | 超时                        |
| ---- | ---------- | -------- | ------- | --------------------------- |
| 插入 | add(o)     | offer(o) | put(o)  | offer(o, timeout, timeunit) |
| 移除 | remove(o)  | poll(o)  | take(o) | poll(timeout, timeunit)     |
| 检查 | element(o) | peek(o)  |         |                             |

四组不同的行为方式解释:

- 抛异常: 如果试图进行的操作无法立即执行，抛一个异常。
- 特定值: 如果试图进行的操作无法立即执行，返回一个特定的值(常常是 true / false)。
- 阻塞: 如果试图进行的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。
- 超时: 如果试图进行的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。

无法向一个 BlockingQueue 中插入 null。如果你试图插入 null，BlockingQueue 将会抛出一个 NullPointerException。 可以访问到 BlockingQueue 中的所有元素，而不仅仅是开始和结束的元素。比如说，你将一个对象放入队列之中以等待处理，但你的应用想要将其取消掉。那么你可以调用诸如 remove(o) 方法来将队列之中的特定对象进行移除。但是这么干效率并不高(译者注: 基于队列的数据结构，获取除开始或结束位置的其他对象的效率不会太高)，因此你尽量不要用这一类的方法，除非你确实不得不那么做。



### BlockingQueue 的例子

这里是一个 Java 中使用 BlockingQueue 的示例。本示例使用的是 BlockingQueue 接口的 ArrayBlockingQueue 实现。 首先，BlockingQueueExample 类分别在两个独立的线程中启动了一个 Producer 和 一个 Consumer。Producer 向一个共享的 BlockingQueue 中注入字符串，而 Consumer 则会从中把它们拿出来。

```java
package com.lv.multithread.collections;

import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;

/**
 * 测试BlockingQueue
 */
public class BlockingQueue_T1 {
    public static void main(String[] args) throws Exception {

        BlockingQueue queue = new ArrayBlockingQueue(1024);

        Producer producer = new Producer(queue);
        Consumer consumer = new Consumer(queue);
		
        new Thread(producer).start();
        new Thread(consumer).start();

        Thread.sleep(4000);
    }

    public static class Producer implements Runnable{

        protected BlockingQueue queue = null;

        public Producer(BlockingQueue queue) {
            this.queue = queue;
        }

        public void run() {
            try {
                queue.put("1");
                Thread.sleep(1000);
                queue.put("2");
                Thread.sleep(1000);
                queue.put("3");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    public static class Consumer implements Runnable{

        protected BlockingQueue queue = null;

        public Consumer(BlockingQueue queue) {
            this.queue = queue;
        }

        public void run() {
            try {
                //阻塞等待
                System.out.println(queue.take());
                System.out.println(queue.take());
                System.out.println(queue.take());
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

  
    
```

结果

> 1
> 2
> 3

 Producer 类。注意它在每次 put() 调用时是如何休眠一秒钟的。这将导致 Consumer 在等待队列中对象的时候发生阻塞

### 数组阻塞队列 ArrayBlockingQueue

**ArrayBlockingQueue 类实现了 BlockingQueue 接口。**

ArrayBlockingQueue 是一个**有界的阻塞**队列，其内部实现是**将对象放到一个数组**里。有界也就意味着，它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限，但之后就无法对这个上限进行修改了(译者注: 因为它是基于数组实现的，也就具有数组的特性: 一旦初始化，大小就无法修改)。 ArrayBlockingQueue 内部以 **FIFO(先进先出)**的顺序对元素进行存储。 以下是在使用  ArrayBlockingQueue 的时候对其初始化的一个示例:

```java
BlockingQueue queue = new ArrayBlockingQueue(1024);
queue.put("1");
Object object = queue.take();
  
    
```

以下是使用了 Java 泛型的一个 BlockingQueue 示例。注意其中是如何对 String 元素放入和提取的:

```java
BlockingQueue<String> queue = new ArrayBlockingQueue<String>(1024);
queue.put("1");
String string = queue.take();

```

### 延迟队列 DelayQueue

DelayQueue是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。这种队列是有序的，即队头对象的延迟到期时间最长。注意：不能将null元素放置到这种队列中。

DelayQueue能做什么？
在我们的业务中通常会有一些需求是这样的：

1. 淘宝订单业务:下单之后如果三十分钟之内没有付款就自动取消订单。
2. 饿了吗订餐通知:下单成功后60s之后给用户发送短信通知。

那么这类业务我们可以总结出一个特点:需要延迟工作。
由此的情况，就是我们的DelayQueue应用需求的产生。

DelayQueue 接口定义:

```java
public interface Delayed extends Comparable<Delayed>{
    public long getDelay(TimeUnit timeUnit);
}
  
```

DelayQueue 将会在每个元素的 getDelay() 方法返回的值的时间段之后才释放掉该元素。如果返回的是 0 或者负值，延迟将被认为过期，该元素将会在 DelayQueue 的下一次 take  被调用的时候被释放掉。

传递给 getDelay 方法的 getDelay 实例是一个枚举类型，它表明了将要延迟的时间段。TimeUnit 枚举将会取以下值:

- DAYS
- HOURS
- INUTES
- SECONDS
- MILLISECONDS
- MICROSECONDS
- NANOSECONDS

其通过remove（Object o）来移除，o是我们的元素。通过查看remove的实现可知。其内是通过equals比较两个对象是否相等来判断是否是同一个delayed。所以我们需要在我们的QueueDelayed中实现我们的equals方法，使其两个对象之间的相等能够进行判断。

通过实现compareTo 方法排序决定队列元素的先后顺序

例子：

```
com.lv.multithread.collections.DelayQueue
```

### 链阻塞队列 LinkedBlockingQueue

LinkedBlockingQueue 类实现了 BlockingQueue 接口。

LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用 Integer.MAX_VALUE 作为上限。

LinkedBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个，而尾元素则是最短的那个。 以下是 LinkedBlockingQueue 的初始化和使用示例代码:

```java
BlockingQueue<String> unbounded = new LinkedBlockingQueue<String>();
BlockingQueue<String> bounded   = new LinkedBlockingQueue<String>(1024);
bounded.put("Value");
String value = bounded.take();
    
```



### 具有优先级的阻塞队列 PriorityBlockingQueue

PriorityBlockingQueue 类实现了 BlockingQueue 接口。

PriorityBlockingQueue 是一个无界的并发队列。它使用了和类 java.util.PriorityQueue 一样的排序规则。你无法向这个队列中插入 null 值。 所有插入到 PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。 注意 PriorityBlockingQueue 对于具有相等优先级(compare() == 0)的元素并不强制任何特定行为。

同时注意，如果你从一个 PriorityBlockingQueue 获得一个 Iterator 的话，该 Iterator 并不能保证它对元素的遍历是以优先级为序的。 以下是使用 PriorityBlockingQueue 的示例:

```java
BlockingQueue queue   = new PriorityBlockingQueue();
//String implements java.lang.Comparable
queue.put("Value");
String value = queue.take();

    
```

### 同步队列 SynchronousQueue

SynchronousQueue 类实现了 BlockingQueue 接口。

SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。 据此，把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。

### BlockingDeque

java.util.concurrent 包里的 BlockingDeque 接口表示一个线程安放入和提取实例的双端队列。

BlockingDeque 类是一个双端队列，在不能够插入元素时，它将阻塞住试图插入元素的线程；在不能够抽取元素时，它将阻塞住试图抽取的线程。 deque(双端队列) 是 "Double Ended Queue" 的缩写。因此，双端队列是一个你可以从任意一端插入或者抽取元素的队列。

在线程既是一个队列的生产者又是这个队列的消费者的时候可以使用到 BlockingDeque。如果生产者线程需要在队列的两端都可以插入数据，消费者线程需要在队列的两端都可以移除数据，这个时候也可以使用 BlockingDeque。BlockingDeque 图解:

<img src="D:\system\custom_code\demo-jdk\src\resources\note\多线程\image\java-thread-x-blocking-deque-1.png" alt="img" style="zoom:100%;"  align="left"/>

##### BlockingDeque 的方法

一个 BlockingDeque - 线程在双端队列的两端都可以插入和提取元素。 一个线程生产元素，并把它们插入到队列的任意一端。如果双端队列已满，插入线程将被阻塞，直到一个移除线程从该队列中移出了一个元素。如果双端队列为空，移除线程将被阻塞，直到一个插入线程向该队列插入了一个新元素。

BlockingDeque 具有 4 组不同的方法用于插入、移除以及对双端队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下:

|      | 抛异常         | 特定值        | 阻塞         | 超时                             |
| ---- | -------------- | ------------- | ------------ | -------------------------------- |
| 插入 | addFirst(o)    | offerFirst(o) | putFirst(o)  | offerFirst(o, timeout, timeunit) |
| 移除 | removeFirst(o) | pollFirst(o)  | takeFirst(o) | pollFirst(timeout, timeunit)     |
| 检查 | getFirst(o)    | peekFirst(o)  |              |                                  |

|      | 抛异常        | 特定值       | 阻塞        | 超时                            |
| ---- | ------------- | ------------ | ----------- | ------------------------------- |
| 插入 | addLast(o)    | offerLast(o) | putLast(o)  | offerLast(o, timeout, timeunit) |
| 移除 | removeLast(o) | pollLast(o)  | takeLast(o) | pollLast(timeout, timeunit)     |
| 检查 | getLast(o)    | peekLast(o)  |             |                                 |

四组不同的行为方式解释:

- 抛异常: 如果试图的操作无法立即执行，抛一个异常。
- 特定值: 如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。
- 阻塞: 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。
- 超时: 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。

### BlockingDeque 与BlockingQueue关系

BlockingDeque 接口继承自 BlockingQueue 接口。这就意味着你可以像使用一个 BlockingQueue 那样使用 BlockingDeque。如果你这么干的话，各种插入方法将会把新元素添加到双端队列的尾端，而移除方法将会把双端队列的首端的元素移除。正如 BlockingQueue 接口的插入和移除方法一样。

以下是 BlockingDeque 对 BlockingQueue 接口的方法的具体内部实现:

| BlockingQueue | BlockingDeque   |
| ------------- | --------------- |
| add()         | addLast()       |
| offer() x 2   | offerLast() x 2 |
| put()         | putLast()       |
| remove()      | removeFirst()   |
| poll() x 2    | pollFirst()     |
| take()        | takeFirst()     |
| element()     | getFirst()      |
| peek()        | peekFirst()     |



既然 BlockingDeque 是一个接口，那么你想要使用它的话就得使用它的众多的实现类的其中一个。java.util.concurrent 包提供了以下 BlockingDeque 接口的实现类: LinkedBlockingDeque。

以下是如何使用 BlockingDeque 方法的一个简短代码示例:

```java
BlockingDeque<String> deque = new LinkedBlockingDeque<String>();
deque.addFirst("1");
deque.addLast("2");
 
String two = deque.takeLast();
String one = deque.takeFirst();
  
    
```

### 链阻塞双端队列 LinkedBlockingDeque

LinkedBlockingDeque 类实现了 BlockingDeque 接口。内部是双向链式结构(链接节点)

deque(双端队列) 是 "Double Ended Queue" 的缩写。因此，双端队列是一个你可以从任意一端插入或者抽取元素的队列。

LinkedBlockingDeque 是一个双端队列，在它为空的时候，一个试图从中抽取数据的线程将会阻塞，无论该线程是试图从哪一端抽取数据。

以下是 LinkedBlockingDeque 实例化以及使用的示例:

```java
BlockingDeque<String> deque = new LinkedBlockingDeque<String>();
deque.addFirst("1");
deque.addLast("2");
 
String two = deque.takeLast();
String one = deque.takeFirst();
  
```

### TransferQueue

参考地址：https://blog.csdn.net/qq_38293564/article/details/80593821

应用场景：当我们不想生产者过度生产消息时，TransferQueue可能非常有用，可避免发生OutOfMemory错误。在这样的设计中，消费者的消费能力将决定生产者产生消息的速度。

TransferQueue(java7引入)继承了BlockingQueue（BlockingQueue又继承了Queue）并扩展了一些新方法。**生产者会一直阻塞直到所添加到队列的元素被某一个消费者所消费（不仅仅是添加到队列里就完事）**

```java
public interface TransferQueue<E> extends BlockingQueue<E> {
    // 如果存在一个消费者已经等待接收它，则立即传送指定的元素，否则返回false，并且不进入队列。
    boolean tryTransfer(E e);
    // 如果存在一个消费者已经等待接收它，则立即传送指定的元素，否则等待直到元素被消费者接收。
    void transfer(E e) throws InterruptedException;
    // 在上述方法的基础上设置超时时间
    boolean tryTransfer(E e, long timeout, TimeUnit unit)
        throws InterruptedException;
    // 如果至少有一位消费者在等待，则返回true
    boolean hasWaitingConsumer();
    // 获取所有等待获取元素的消费线程数量
    int getWaitingConsumerCount();
}
```



#### LinkedTransferQueue

> LinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法。
>
> LinkedTransferQueue采用一种预占模式。意思就是消费者线程取元素时，如果队列不为空，则直接取走数据，若队列为空，那就生成一个节点（节点元素为null）入队，然后消费者线程被等待在这个节点上，后面生产者线程入队时发现有一个元素为null的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的方法返回。我们称这种节点操作为“匹配”方式。
>
> 它出现在JDK7中。Doug Lea 大神说LinkedTransferQueue是一个聪明的队列。它是ConcurrentLinkedQueue、SynchronousQueue (公平模式下)、无界的LinkedBlockingQueues等的超集。
> 



## Atomic

### 原子更新基本类型

使用原子的方式更新基本类型，Atomic包提供了以下3个类。

- AtomicBoolean: 原子更新布尔类型。
- AtomicInteger: 原子更新整型。
- AtomicLong: 原子更新长整型。

AtomicInteger

> 总结方法：get在前面的都是返回旧值，get在后面的都是返回新值

```java
//测试地址路径：com.lv.multithread.atomic.AtomicInteger_T1   
		//函数式接口,对新值与旧值进行自定义函数的计算，第一个参数为新值，第二个计算函数
		//atomicInteger.accumulateAndGet 
      
		//函数值接口，对旧值进行自定义函数的计算，参数为自定义函数，返回旧值
        //atomicInteger.getAndUpdate 
		//函数值接口，对旧值进行自定义函数的计算，参数为自定义函数，返回新值
        //atomicInteger.updateAndGet 
      	//设置给定值
         atomicInteger.set(10);
        //得到当前值
         atomicInteger.get();
        //得到并累加
        atomicInteger.addAndGet(10);
        //得到值后进行累加，返回累加前的值
        atomicInteger.getAndAdd(10);
        //自减1，返回自减后的值 相当--i
        atomicInteger.decrementAndGet();
        //自增1，返回自增后的值 相当++i
        atomicInteger.incrementAndGet();
        //参数1为预期值，如果预期值等于21，则更新为第二个值，并且返回true ,否则返回返回false
        atomicInteger.compareAndSet(21,20);
        //参数1为预期值，如果预期值等于21，则更新为第二个值，并且返回true ,否则返回返回false,目前看源码好像与compareAndSet一致
        atomicInteger.weakCompareAndSet(21,20);
        //自增1 ,返回的是以前的值,相当于i++
        atomicInteger.getAndIncrement();
        //自增1 ,返回的是以前的值,相当于i--
        atomicInteger.getAndDecrement();
        //设置新值，返回旧值
        atomicInteger.getAndSet(10);

```

### DoubleAdder

```java
public class DoubleAdder_T1 {
   static DoubleAdder doubleAdder=new DoubleAdder();

    public static void main(String[] args) {
        doubleAdder.add(1); //加1
        System.out.println(doubleAdder);
        doubleAdder.reset(); //重置为0
        System.out.println(doubleAdder);
        doubleAdder.add(1); //加1
        System.out.println(doubleAdder.sumThenReset()); //返回合计后进行重置为0
    }
}
```



### 原子更新引用类型

- AtomicReference: 原子更新引用类型。
- AtomicStampedReference: 原子更新引用类型, 内部使用Pair来存储元素值及其版本号。
- AtomicMarkableReferce: 原子更新带有标记位的引用类型。

#### AtomicReference

​	保证对象的引用线程安全，改变值不影响更新值

```java
public static void main(String[] args) {
        Student s1 = new Student(1, "张三");
        AtomicReference<Student> atomicReference=new AtomicReference<>(s1);
        System.out.println(atomicReference);
        s1=new Student(1, "张三");
        atomicReference.compareAndSet(s1,new Student(2, "张三"));
        System.out.println(atomicReference);

    }

/*
输出结果
Student{age=3, name='张三2'}
Student{age=3, name='张三2'}
*/
```

#### AtomicStampedReference

​	解决ABA问题，通过int类型的版本号进行判断，必须旧版本号与旧值相同才能更新

#### AtomicMarkableReference

>    	解决ABA问题，通过Boolean类型进行版本判断

###  原子更新数组

通过原子的方式更新数组里的某个元素，Atomic包提供了以下的3个类：

- AtomicIntegerArray: 原子更新整型数组里的元素。
- AtomicLongArray: 原子更新长整型数组里的元素。
- AtomicReferenceArray: 原子更新引用类型数组里的元素。  这三个类的最常用的方法是如下两个方法

###   原子更新字段类

Atomic包提供了四个类进行原子字段更新：

- AtomicIntegerFieldUpdater: 原子更新整型的字段的更新器。
- AtomicLongFieldUpdater: 原子更新长整型字段的更新器。
- AtomicStampedFieldUpdater: 原子更新带有版本号的引用类型。
- AtomicReferenceFieldUpdater: 上面已经说过此处不在赘述。



这四个类的使用方式都差不多，是基于反射的原子更新字段的值。要想原子地更新字段类需要两步:

- 第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。

- 第二步，更新类的字段必须使用public volatile修饰。

  ```java
  public class TestAtomicIntegerFieldUpdater {
  
      public static void main(String[] args){
          TestAtomicIntegerFieldUpdater tIA = new TestAtomicIntegerFieldUpdater();
          tIA.doIt();
      }
  
      public AtomicIntegerFieldUpdater<DataDemo> updater(String name){
          return AtomicIntegerFieldUpdater.newUpdater(DataDemo.class,name);
  
      }
  
      public void doIt(){
          DataDemo data = new DataDemo();
          System.out.println("publicVar = "+updater("publicVar").getAndAdd(data, 2));
          /*
              * 由于在DataDemo类中属性value2/value3,在TestAtomicIntegerFieldUpdater中不能访问
              * */
          //System.out.println("protectedVar = "+updater("protectedVar").getAndAdd(data,2));
          //System.out.println("privateVar = "+updater("privateVar").getAndAdd(data,2));
  
          //System.out.println("staticVar = "+updater("staticVar").getAndIncrement(data));//报java.lang.IllegalArgumentException
          /*
              * 下面报异常：must be integer
              * */
          //System.out.println("integerVar = "+updater("integerVar").getAndIncrement(data));
          //System.out.println("longVar = "+updater("longVar").getAndIncrement(data));
      }
  
  }
  
  class DataDemo{
      public volatile int publicVar=3;
      protected volatile int protectedVar=4;
      private volatile  int privateVar=5;
  
      public volatile static int staticVar = 10;
      //public  final int finalVar = 11;
  
      public volatile Integer integerVar = 19;
      public volatile Long longVar = 18L;
  
  }
  
  ```

  







# JMH与Disruptor



今天我们讲两个内容，第一个是JMH，第二个是Disruptor。这两个内容是给大家做更进一步的这种多线程和高并发的一些专业上的处理。生产环境之中我们很可能不自己定义消息队列，而是使用Disruptor。我们生产环境做测试的时候也不是像我说的那样写一个start写一个end就测试完了。在这里给大家先介绍专业的JMH测试工具，在给大家介绍Disruptor号称最快的消息队列。 

**JMH -java Microbenchmark Harness**

微基准测试，他是测的某一个方法的性能到底是好或者不好，换了方法的实现之后他的性能到底好还是不好。

这个测试的框架是2013年发出来的，由JLT的开发人员开发，后来归到了OpenJDK下面。

**官网**

http://openjdk.java.net/projects/code-tools/jmh/

下面我们来介绍什么是一个JMH，他是用来干什么的，我们来看到底怎么使用，给大家一个简单的介绍肯定是了解不了jmh是个什么东西，已经把这个步骤给大家总结一篇文档，官网在哪里，怎么样去创建一个JMH的测试，创建一共大致有七个步骤，还有他的一些基本概念，什么叫预热，什么叫Mesurement等等的，还有进一步了解的官方地址。

## JMH Java准测试工具套件

## 什么是JMH

### 官网

 http://openjdk.java.net/projects/code-tools/jmh/ 

## 创建JMH测试

1. 创建Maven项目，添加依赖，我们需要添加两个依赖：

   1.1：jmh-core （jmh的核心)

   1.2：jmh-generator-annprocess（注解处理包） 

   ```java
   <?xml version="1.0" encoding="UTF-8"?>
   <project xmlns="http://maven.apache.org/POM/4.0.0"
            xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
            xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
       <modelVersion>4.0.0</modelVersion>
   
       <properties>
           <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
           <encoding>UTF-8</encoding>
           <java.version>1.8</java.version>
           <maven.compiler.source>1.8</maven.compiler.source>
           <maven.compiler.target>1.8</maven.compiler.target>
       </properties>
   
       <groupId>mashibing.com</groupId>
       <artifactId>HelloJMH2</artifactId>
       <version>1.0-SNAPSHOT</version>
   
   
       <dependencies>
           <!-- https://mvnrepository.com/artifact/org.openjdk.jmh/jmh-core -->
           <dependency>
               <groupId>org.openjdk.jmh</groupId>
               <artifactId>jmh-core</artifactId>
               <version>1.21</version>
           </dependency>
   
           <!-- https://mvnrepository.com/artifact/org.openjdk.jmh/jmh-generator-annprocess -->
           <dependency>
               <groupId>org.openjdk.jmh</groupId>
               <artifactId>jmh-generator-annprocess</artifactId>
               <version>1.21</version>
               <scope>test</scope>
           </dependency>
       </dependencies>
   
   
   </project>
   ```

2. idea安装JMH插件 JMH plugin v1.0.3

   JMH这个东西你要想真正的安安静静的去运行，就不会去影响我们正常程序的执行，最好的方式就是按照官网的说法是命令行的方式，比方说你要测试某一个包里面的类的话你应该把这个类和其他的依赖类打成一个jar包，然后单独的把这个jar包放到某一个机器上，在这个机器上对这个jar包进行微基准的测试，如果对他进行测试的比较好，那说明最后的结果还可以，如果说边开发边进行这种微基准的测试实际上他非常的不准，因为你的开发环境会对结果产生影响。只不过我们自己开发人员来说平时你要想进行一些微基准的测试的话，你要是每次打个包来进行正规一个从头到尾的测试 ，完了之后发现问题不对再去重新改，效率太低了。所以在这里教大家的是怎么样在IDE里面来进行微基准的测试。idea安装JMH插件：file->Settings->Plugins->JMH-plugin。它运行的时候需要这个plugin的支持，如果你用命令行是不需要这些东西的。

3. 由于用到了注解，打开运行程序注解配置

   因为JMH在运行的时候他用到了注解，注解这个东西你自己得写一个程序得解释他，所以你要把这个给设置上允许JMH能够对注解进行处理：

   > compiler -> Annotation Processors -> Enable Annotation Processing

4. 定义需要测试类PS (ParallelStream)

   看这里，写了一个类，并行处理流的一个程序，定义了一个list集合，然后往这个集合里扔了1000个数。写了一个方法来判断这个数到底是不是一个质数。写了两个方法，第一个是用forEach来判断我们这1000个数里到底有谁是质数；第二个是使用了并行处理流，这个forEach的方法就只有单线程里面执行，挨着牌从头拿到尾，从0拿到1000，但是并行处理的时候会有多个线程采用ForkJoin的方式来把里面的数分成好几份并行的尽兴处理。一种是串行处理，一种是并行处理，都可以对他们进行测试，但需要注意这个基准测试并不是对比测试的，你只是侧试一下你这方法写出这样的情况下他的吞吐量到底是多少，这是一个非常专业的测试的工具。严格的来讲这部分是测试开发专业的。

   ```java
   package com.mashibing.jmh;
   import java.util.ArrayList;
   import java.util.List;
   import java.util.Random;
   
   public class PS {
   
   	static List<Integer> nums = new ArrayList<>();
   	static {
   		Random r = new Random();
   		for (int i = 0; i < 10000; i++) nums.add(1000000 + r.nextInt(1000000));
   	}
   
   	static void foreach() {
   		nums.forEach(v->isPrime(v));
   	}
   
   	static void parallel() {
   		nums.parallelStream().forEach(PS::isPrime);
   	}
   	
   	static boolean isPrime(int num) {
   		for(int i=2; i<=num/2; i++) {
   			if(num % i == 0) return false;
   		}
   		return true;
   	}
   }
   ```

5. 写单元测试

   > 这个测试类一定要在test package下面
   >
   > 我对这个方法进行测试testForEach，很简单我就调用PS这个类的foreach就行了，对它测试最关键的是我加了这个注解@Benchmark，这个是JMH的注解，是要被JMH来解析处理的，这也是我们为么要把那个Annotation Processing给设置上的原因，非常简单，你只要加上注解就可以对这个方法进行微基准测试了，点击右键直接run。
   >
   > ```java
   > package com.mashibing.jmh;
   > 
   > import org.openjdk.jmh.annotations.Benchmark;
   > 
   > import static org.junit.jupiter.api.Assertions.*;
   > 
   > public class PSTest {
   > @Benchmark
   > @Warmup（iteration=1, time=3）//在专业测试里面首先要进行预热，预热多少次，预热多少时间
   > @Fork(5)//意思是用多少个线程去执行我们的程序
   > @BenchmarkMode(Mode.Throughput)//是对基准测试的一个模式，这个模式用的最多的是Throughput吞吐量
   > @Measurement(iteration=1, time=3)//是整个测试要测试多少遍，调用这个方法要调用多少次 
   > public void testForEach() {
   >   PS.foreach();
   > }
   > }
   > ```

6. 运行测试类，如果遇到下面的错误：

   ```java
   ERROR: org.openjdk.jmh.runner.RunnerException: ERROR: Exception while trying to acquire the JMH lock (C:\WINDOWS\/jmh.lock): C:\WINDOWS\jmh.lock (拒绝访问。), exiting. Use -Djmh.ignoreLock=true to forcefully continue.
   	at org.openjdk.jmh.runner.Runner.run(Runner.java:216)
   	at org.openjdk.jmh.Main.main(Main.java:71)
   ```

   这个错误是因为JMH运行需要访问系统的TMP目录，解决办法是：

   打开RunConfiguration -> Environment Variables -> include system environment viables

7. 阅读测试报告

**JMH中的基本概念**

1. Warmup
   预热，由于JVM中对于特定代码会存在优化（本地化），预热对于测试结果很重要
2. Mesurement
   总共执行多少次测试
3. Timeout

4. Threads
   线程数，由fork指定
5. Benchmark mode
   基准测试的模式
6. Benchmark
   测试哪一段代码

**next**

做个是JMH的一个入门，严格来讲这个和我们的关系其实并不大，这个是测试部门干的事儿，但是你了解一下没有特别多的坏处，你也知道你的方法最后效率高或者底，可以通过一个简单的JMH插件来帮你完成，你不要在手动的去写这件事儿了。

如果说大家对JMH有兴趣，你们在工作中可能会有用的上大家去读一下官方的例子，官方大概有好几十个例子程序，你可以自己一个一个的去研究。

官方样例：
http://hg.openjdk.java.net/code-tools/jmh/file/tip/jmh-samples/src/main/java/org/openjdk/jmh/samples/





**Disruptor**

按照英文翻译的话，Disruptor应该是分裂、瓦解。这个Disruptor是一个做金融的、做股票的这样一个公司交易所来开发的，为自己来开发的这么一个底层的框架，开发出来之后受到了很多的认可，开源之后，2011年获得Duke将。如果你想把它用作MQ的话，单机最快的MQ。性能非常的高，主要是它里面用的全都是cas，另外把各种各样的性能开发到了极致，所以他单机支持很高的一个并发。

Disruptor不是平时我们学的这个redis、不是平时我们所学的kafka，他可以跟他们一样有类似的用途，但他是单机，redis、kafka也可以用于集群。redis他有这种序列化的机制，就是你可以把它存储到硬盘上或数据库当中是可以的，kafka当然也有，Disruptor没有，Disruptor就是在内存里，Disruptor简单理解就是内存里用于存放元素的一个高效率的队列。



**介绍**

关于Disruptor的一些资料，给大家列在这里。

主页：http://imax-exchange.github.io/disruptor/

源码：https://github.com/LMAX-Exchange/disruptor

GettingStarted:https://github.com/LMAX-Exchange/disruptor/wiki/Getting-Started

api:http://imax-exchange.github.io/disruptor/docs/index.html

maven:https://mvnrepository.com/artifact/com.imax/disruptor



Disruptor叫无锁、高并发、环形Buffer，直接覆盖（不用清除）旧的数据，降低GC频率，用于生产者消费者模式（如果说按照设计者角度来讲他就是观察者模式）。什么叫观察者模式，想象一下，我们在前面学各种各样的队列的时候，队列就是个容器，好多生产者往里头扔东西，好多消费者从里头往外拿东西。所谓的生产者消费者就是这个意思，为什么我们可以叫他观察者呢，因为这些消费者正在观察着里面有没有新东西，如果有的话我马上拿过来消费，所以他也是一种观察者模式。Disruptor实现的就是这个容器

**Disruptor核心与特点**

Disruptor也是一个队列，和其他队列不一样的是他是一个环形队列，环形的Buffer。一般情况下我们的容器是一个队列，不管你是用链表实现还是用数组实现的，它会是一个队列，那么这个队列生产者这边使劲往里塞，消费者这边使劲往外拿，但Disruptor的核心是一个环形的buffer。

![09_01](img/09_01.jpg)

- 对比ConcurrentLinkedQueue：链表实现

  这种环形的buffer速度就是更快，同学们可以去查一下JDK自带的容器，你会发现效率比较高的有各种各样的队列，如果不想阻塞就可以用Concurrent相关的，ConcurrentLinkedQueue是并发的用链表实现的队列，它里面大量的使用了cas，因此它的效率相对比较高，可是对于遍历来讲链表的效率一定会比数组低。

- JDK中没有ConcurrentArrayQueue

  因为数组的大小的固定的，如果想扩展的话就要把原来的数组拷贝到新数组里，每次加都要拷贝这个效率相当底，所以他并没有给大家加这个叫ConcurrentArrayQueue，但是Disruptor就非常牛X，想到了这样一个办法，就是把数组的头尾相连。

- Disruptor是用数组实现的

  这样的一个队列，你可以认为Disruptor就是用数组实现的ConcurrentArrayQueue，另外这个Queue是首尾相连的

那Disruptor用数组实现的环形的就比上面两个都牛吗，牛在哪？为啥呢？如果我们用ConcurrentLinkedQueue这里面就是一个一个链表，这个链表遍历起来肯定没有数组快，这个是一点。还有第二点就是这个链表要维护一个头指针和一个尾指针，我往头部加的时候要加锁，往尾部拿的时候也要加锁。另外链表本身效率就偏低，还要维护两个指针。关于环形的呢，环形本身就维护一个位置，这个位置称之为sequence序列，这个序列代表的是我下一个有效的元素指在什么位置上，就相当于他只有一个指针来回转。加在某个位置上怎么计算：直接用那个数除以我们整个的容量求余就可以了。

- RingBuffer是一个环形队列

- RingBuffer的序号，指向下一个可用的元素

- 采用数组实现，没有首尾指针

- 对比ConcurrentLinkedQueue，用数组实现的速度更快

  假如长度为8，当添加到第12个元素的时候在哪个序号上呢？用12%8决定

  当Buffer被填满的时候到底是覆盖还是等待，由Produce决定

  长度设为2的n次幂，利于二进制计算，例如：12%8=12&（8-1）

如果大家对于位运算有疑问的，在咱们网站上有一个菜鸟预习，里面有一部分是二进制，大家去翻看一下。

由于它会采用覆盖的方式，所以他没有必要记头指针，没有必要记尾指针。我只要记一个指针放在这就可以了。在这点上依然要比ConcurrentLinkedQueue要快。

那我生产者线程生产的特别多，消费者没来得及消费那我在往后覆盖的话怎么办？不会那么轻易的让你覆盖的，我们是有策略的，我生产者生产满了，要在生产一个的话就马上覆盖这个位置上的数了。这时候是不能覆盖的，指定了一个策略叫等待策略，这里面有8中等待策略，分情况自己去用。最常见的是BlockingWait，满了我就在这等着，什么时候你空了消费者来唤醒一下就继续。



### Disruptor开发步骤

开发步骤是比较固定的一个开发步骤。

1：定义Event-队列中需要处理的元素。

​	在Disruptor他是每一个消息都认为是一个事件，在他这个概念里就是一个事件，所以在这个环形队列里面存的是一个一个的Event。

2：定义Event工厂，用于填充队列

​	那这个Event怎么产生，就需要指定Event的工厂。

3：定义EventHandler(消费者)，处理容器中的元素

​	那这个Event怎么消费呢，就需要指定Event的消费者EventHandler。

下面我们直接看程序，先看来自官网的几个辅助程序：LongEvent这个事件里面或者说消息里面装的什么值，我只装了一个long值，但这里面可以装任何值，任何类型的都可以往里装，这个long类型的值我们可以指定他set，官网上没有toString方法，我给大家加了一段主要是为了打印消息让大家看的更清楚。

```java
package com.mashibing.disruptor;
public class LongEvent
{
  	private long value;
  
  	public void set(long value)
    {
      	this.value = value;
    }
  
  	@Override
  	public String toString(){
      	return "LongEvent{" +
          			"value=" + value +
          			"}";
    }
}
```

然后呢，我需要一个EventFactory就是怎么产生这些个事件，这个Factory非常简单，LongEventFactory去实现EventFactiry的接口，去重写它的newInstance方法直接new  LongEvent。构建这个环的时候为什么要指定一个产生事件的工厂，我直接new这个事件不可以吗？但是有的事件里面的构造方法不让你new呢，产生事件工厂的话你可以灵活的指定一些 ，这里面也是牵扯到效率的。底层比较深，我给大家解释一下：

这里牵扯效率问题，因为Disruptor初始化的时候会调用Event工厂，对ringBuffer进行内存的提前分配，GC频率会降低。

```java
package com.mashibing.disruptor;

import com.lmax.disruptor.EventFactory;
public class LongEventFactory implements EventFactiry<LongEvent>{
  	
  	@Override
  	public LongEvent newInstance(){
      	return new LongEvent();
    }
}
```

在看第三个叫LongEventHandler，Handler就是我拿到这个事件之后该怎么样进行处理，所以这里是消息的消费者，怎么处理呢，很简单，我处理完这个消息之后呢就记一个数，总共记下来我一共处理了多少消息了，处理消息的时候默认调用的是onEvent方法，这个方法里面有三个参数，第一个是你要处理的那个消息，第二个是你处理的是哪个位置上的消息，第三个是整体的消息结束没结束，是不是处理完了。你可以判断他如果是true的话消费者就可以退出了，如果是false的话说明后面还有继续消费。

```java
package com.mashibing.disruptor;

import com.lmax.disruptor.EventHandler;

public class LongEventHandler implements EventHandler<LongEvent>{
  	/**
  	*
  	*@param event
  	*@param sequence RingBuffer的序号
  	*@param endOfBatch 是否为最后一个元素
  	*@throws Exception
  	**/
  	
  	public static long count = 0;
  	
  	@Override
  	public void onEvent(LongEvent event,long sequence,boolean endOfBatch) throws Exception{
	      count++;	
      	System.out.println("["+Thread.currentThread().getName()+"]"+event+"序号："+sequence);
    }
}

```

所以我们定义了这三个类，关于这三个类在给大家解释一下，我们现在有一个环，然后这个环上每一个位置装LongEvent，怎么产生这个LongEvent通过这个LongEventFactory的newInstance方法来产生，当我拿到这个Event之后通过LongEventHandler进行处理。

到现在我们把这三个辅助类都已经定义好了，定义好的情况下我们怎么才能比较有机的结合在一起，让他在Disruptor进行处理呢，看第一个小例子程序，首先把EvenFactory给他初始化了new LongEventFactory，我们这个环应该是2的N次方1024，然后new一个Disruptor出来，需要指定这么几个参数：factory产生消息的工厂；bufferSize是指定这个环大小到底是多少；defaultThreadFactory线程工厂，指的是当他要产生消费者的时候，当要调用这个消费者的时候他是在一个特定的线程里执行的，这个线程就是通过defaultThreadFactory来产生；

继续往下看，当我们拿到这个消息之后怎么进行处理啊，我们就用这个LongEventHandler来处理。然后start，当start之后一个环起来了，每个环上指向的这个LongEvent也得初始化好，内存分配好了，整个就安安静静的等待着生产者的到来。

看生产者的代码，long sequence = ringBuffer.next()，通过next找到下一个可用的位置，最开始这个环是空的，下一个可用的位置是0这个位置，拿到这个位置之后直接去ringBuffer里面get(0)这个位置上的event。如果说你要是追求效率的极致，你应该是一次性全部初始化好，你get的时候就不用再去判断，如果你想做一个延迟，很不幸的是你每次都要做判断是不是初始化了。get的时候就是拿到一个event，这个是我们new出来的默认的，但是我们可以改里面的event.set( 值...)，填好数据之后ringBuffer.publish发布生产。

```java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main01
{
  	public static void main(String[] args) thrwos Exception
    {
      	//the factory for the event
      	LongEvenFactory factory = new LongEventFactory();
      	
      	//Specify the of the ring buffer,must be power of 2.
      	int bufferSize = 1024;
      
      	//Construct the Disruptor
      	Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, Executors.defaultThreadFactory());
      
      	//Connect the handler
      	disruptor.handleEventsWith(new LongEventHandler());
      
      	//Start the Disruptor,start all threads running
      	disruptor.start();
      
      	//Get the ring buffer form the Disruptor to be used for publishing.
      	RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();
      
      	//官方例程
      	long sequence = ringBuffer.next();//Grab the next sequence
      	try
        {
          	LongEvent event=ringBuffer.get(sequence);//Get the entry in the Disruptor
          	//for the sequence
          	event.set(8888L);//Fill with data
        }
      	finally
        {
          	ringBuffer.publish(sequence);
        }
    }
}

```

disruptor在后面提供了一些Lambda表达式的写法，为了支持这种写法对整个消息的构建过程做了改进，读下面02小程序使用translator，就是怎么样构建这个消息，原来我们都是用消息的factory，但是下面这次我们用translator对他进行构建，就是把某一些数据翻译成消息。前面产生event工厂还是一样，然后bufferSize，后面再扔的是DaemonThreadFactory就是后台线程了，new LongEventHandler然后start拿到他的ringBuffer，前面都一样。只有一个地方叫EventTranslator不一样，我们在main01里面的代码是要写try  catch然后把里面的值给设好，相当于把这个值转换成event对象。相对简单的写法，它会把某些值转成一个LongEvent，通过EventTranslator。new出来后实现了translateTo方法，EventTranslator他本身是一个接口，所以你要new的时候你又要实现它里面没有实现的方法，translateTo的意思是你给我一个Event，我会把这个Event给你填好。ringBuffer.publishEvent(translator1) 你只要把translator1交个ringBuffer就可以了。这个translator就是为了迎合Lambda表达式的写法（为java8的写法做准备）

另外translator有很多种用法：

EventTranslatorOneArg只有带一个参数的EventTranslator。我带有一个参数，这个参数会通过我的translateTo方法转换成一个LongEvent；

既然有EventTranslatorOneArg就有EventTranslatorTwoArg、EventTranslatorThreeArg，还有EventTranslatorVararg多了去了Vararg就是有好多个值，我把里面的值全都给你加起来最后把结果set到event里面。

```java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main02
{
  	public static void main(String[] args) thrwos Exception
    {
      	//the factory for the event
      	LongEvenFactory factory = new LongEventFactory();
      	
      	//Specify the of the ring buffer,must be power of 2.
      	int bufferSize = 1024;
      
      	//Construct the Disruptor
      	Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, DaemonThreadFactory.INSTANCE);
      
      	//Connect the handler
      	disruptor.handleEventsWith(new LongEventHandler());
      
      	//Start the Disruptor,start all threads running
      	disruptor.start();
      
      	//Get the ring buffer form the Disruptor to be used for publishing.
      	RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();
      
      	//========================================================================
      	EventTranslator<LongEvent> translator1 = new EventTranslator<LongEvent>(){
          	@Override
          	public void translateTo(LongEvent event,long sequence){ event.set(8888L); }
        };
      	ringBuffer.publishEvent(translator1);
	      //========================================================================
      	EventTranslatorOneArg<LongEvent,Long> translator2 = new EventTranslatorOneArg<LongEvent,Long>(){
          @Override
          public void translateTo(LongEvent event,long sequence,Long l){ event.set(l); }
        };
      	ringBuffer.publishEvent(translator2,7777L);
      //========================================================================
      	EventTranslatorTwoArg<LongEvent,Long,Long> translator3 = new EventTranslatorTwoArg<LongEvent,Long,Long>(){
          @Override
          public void translateTo(LongEvent event,long sequence,Long l1,Long l2){ event.set(l); }
        };
      	ringBuffer.publishEvent(translator3,10000L,10000L);
       //========================================================================
      	EventTranslatorThreeArg<LongEvent,Long,Long,Long> translator4 = new EventTranslatorThreeArg<LongEvent,Long,Long,Long>(){
          @Override
          public void translateTo(LongEvent event,long sequence,Long l1,Long l2,Long l3){ event.set(l1+ l2+ l3); }
        };
      	ringBuffer.publishEvent(translator4,10000L,10000L,10000L);
      //========================================================================
      	EventTranslatorVararg<LongEvent> translator5 = new EventTranslatorThreeArg<LongEvent>(){
          @Override
          public void translateTo(LongEvent event,long sequence,Object... objects){
          		long result = 0;
            	for(Object o : objects){
                	long l =(Long)o;
                	result +=l;
              }
          }
        };
      	ringBuffer.publishEvent(translator5,10000L,10000L,10000L,10000L);
    }
}
```

有了上面Translator之后呢，下面看Lambda表达式怎么写，这个是比较简洁的写法，连factory都省了，直接指定一个Lambda表达式LongEvent::new。继续handleEventsWith把三个参数传进来后面写好Lambda表达式直接打印，然后start， 接着RingBuffer，publishEvent原来我们还有写try...catch，现在简单了直接ringBuffer.publishEvent（第一个是lambda表达式，表达式后是你指定的几个参数），所以现在的这种写法就不定义各种各样的EventTranslator了。

```java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main03
{
  	public static void main(String[] args) thrwos Exception
    {
      	//the factory for the event
      	LongEvenFactory factory = new LongEventFactory();
      	
      	//Specify the of the ring buffer,must be power of 2.
      	int bufferSize = 1024;
      
      	//Construct the Disruptor
      	Disruptor<LongEvent> disruptor = new Disruptor<>(LongEvent::new, bufferSize,DaemonThreadFactory.INSTANCE);
      
      	//Connect the handler
      	disruptor.handleEventsWith((event,sequence,endOfBatch)->System.out.println("Event:"+event));
      
      	//Start the Disruptor,start all threads running
      	disruptor.start();
      
      	//Get the ring buffer form the Disruptor to be used for publishing.
      	RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();
      
      
      	ringBuffer.publishEvent((event, sequence)-> event.set(10000L)); 
			
      	System.in.read();

    }
}
```

下面我们叫一些细节，这些个细节也不难，讲给大家。第一个细节是我们生产者的时候默认会有好多种生产方式，默认的是多线程生产者，但是假如你确定你整个程序里头只有一个生产者的话那你还能提高效率，就是在你指定Disruptor生产者的线程的方式是SINGLE，生产者的类型ProducerType。

**ProducerType生产者线程模式**

- ProducerType有两种模式ProducerMULTI和Producer.SINGLE
- 默认是MULTI，表示在多线程模式下产生sequence
- 如果确认是单线程生产者，那么可以指定SINGLE，效率会提升
- 如果是多个生产者（多线程），但模式指定为SINGLE，会出什么问题？

假如你的程序里头只有一个生产者还用ProducerMULTI的话，我们对序列来进行多线程访问的时候肯定是要加锁的，所以MULTI里面默认是有锁定处理的，但是假如你只有一个线程这个时候应该吧生产者指定为SINGLE，他的效率更高，因为它里面不加锁。

下面这个小程序，我这里指定的是Producer.SINGLE，但是我生产的时候用的是一堆线程，当我制定了Producer.SINGLE之后相当于内部对于序列的访问就没有锁了，它会把性能发挥到极致，它不会报错，它会把你的消息静悄悄的覆盖了，因此你要小心一点。我这里这个写法是我有50 个线程然后每个线程生产100个数，最后结果正常的话应该是有5000个消费产生。

```java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main04_ProducerType{
  	public static void main(String[] args) thrwos Exception{
      //the factory for the event
      	LongEvenFactory factory = new LongEventFactory();
      	
      	//Specify the of the ring buffer,must be power of 2.
      	int bufferSize = 1024;
      
      	//Construct the Disruptor
      	//Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, Executors.defaultThreadFactory());
      	
  			Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, Executors.defaultThreadFactory(),ProducerType.SINGLE,new BlockingWaitStrategy());
      
      	//Connect the handler
      	disruptor.handleEventsWith(new LongEventHandler());
      
      	//Start the Disruptor,start all threads running
      	disruptor.start();
      
      	//Get the ring buffer form the Disruptor to be used for publishing.
      	RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();
  			
  			//========================================================================
  			final int threadCount = 50;
  			CycliBarrier barrier=new CycliBarrier(threadCount);
  			ExecutorService service = Executors.newCachedThreadPool();
  			for(long i=0; i<threadCount; i++){
          	final long threadNum = i; 
          	service.submit(()->{
              	System.out.printf("Thread %s ready to start!\n",threadNum);
              	try{
                   barrier.await();
                }catch(InterruptedException e){
                   e.printStackTrace();
                }catch(BrokenBarrierException e){
                   e.printStackTrace();
                }
              
              	for(int j=0; j<100;j++){
                  	ringBuffer.publishEvent((event,sequence)->{
                      	event.set(threadNum);
                      	System.out.println("生产了"+threadNum);
                    });
                }
            });
        }
  			
  			service.shutdown();
  			//disruptor.shutdown();
  			TimeUnit.SECONDS.sleep(3);
  			System.out.println(LongEventHandler.count);
    }
}
```



我们再来聊一下等待策略WaitStrategy，有好多种方法，看下面

**等待策略**

- （常用）BlockingWaitStrategy:通过线程堵塞的方式，等待生产者唤醒，被唤醒后，再循环检查依赖的sequence是否已经消费。
- BusySpinWaitStrategy：线程一直自旋等待，可能比较耗cpu
- LiteBlockingWaitStrategy：线程阻塞等待生产者唤醒，与BlockingWaitStrategy相比，区别在signalNeeded.getAndSet，如果两个线程同时访问一个访问waitfor，一个访问signalAll时，可以减少lock加锁次数
- LiteTimeoutBlockingWaitStrategy：与LiteBlockingWaitStrategy相比，设置了阻塞时间，超过时间后抛出异常
- PhasedBackoffWaitStrategy：根据时间参数和传入的等待策略来决定使用那种等待策略
- TimeoutBlockingWaitStrategy：相对于BlockingWaitStrategy来说，设置了等待时间，超过后抛出异常
- （常用）YieldingWaitStrategy：尝试100次，然后Thread.yield()让出cpu
- （常用）SleepingWaitStrategy：sleep

我们常用的BlockingWaitStrategy满了就等着；SleepingWaitStrategy满了就睡一觉，睡醒了看看能不能继续执行了；YieldingWaitStrategy让出cpu，让你消费者赶紧消费，消费完了之后我又回来看看我是不是又能生产了；一般YieldingWaitStrategy效率是最高的，但也要看实际情况适用不适用。

```java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main05_WaitStrategy{
    	public static void main(String[] args) thrwos Exception{
					
          //the factory for the event
          LongEvenFactory factory = new LongEventFactory();

          //Specify the of the ring buffer,must be power of 2.
          int bufferSize = 1024;

          //Construct the Disruptor
          Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, Executors.defaultThreadFactory(),ProducerType.MULTI,new SleepingWaitStrategy());

          //Connect the handler
          disruptor.handleEventsWith(new LongEventHandler());

          //Start the Disruptor,start all threads running
          disruptor.start();

          //Get the ring buffer form the Disruptor to be used for publishing.
          RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();

          //========================================================================
          final int threadCount = 50;
          CycliBarrier barrier=new CycliBarrier(threadCount);
          ExecutorService service = Executors.newCachedThreadPool();
          for(long i=0; i<threadCount; i++){
              final long threadNum = i; 
              service.submit(()->{
                  System.out.printf("Thread %s ready to start!\n",threadNum);
                  try{
                     barrier.await();
                  }catch(InterruptedException e){
                     e.printStackTrace();
                  }catch(BrokenBarrierException e){
                     e.printStackTrace();
                  }

                  for(int j=0; j<100;j++){
                      ringBuffer.publishEvent((event,sequence)->{
                          event.set(threadNum);
                          System.out.println("生产了"+threadNum);
                      });
                  }
              });
          }

          service.shutdown();
          //disruptor.shutdown();
          TimeUnit.SECONDS.sleep(3);
          System.out.println(LongEventHandler.count);
      }
}
```

我们来看多个消费者怎么指定，默认的情况下只有一个消费者，你想要有多个消费者的时候也非常简单，看下面代码我定义了两个消费者h1、h2，disruptor.handleEventsWith(h1,h2)这里面是一个可变参数，所以你要想有多个消费者的时候就往里装，多个消费者是位于多个线程里面的。

```Java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main06_MultiConsumer{
    	public static void main(String[] args) thrwos Exception{
					
          //the factory for the event
          LongEvenFactory factory = new LongEventFactory();

          //Specify the of the ring buffer,must be power of 2.
          int bufferSize = 1024;

          //Construct the Disruptor
          Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, Executors.defaultThreadFactory(),ProducerType.MULTI,new SleepingWaitStrategy());

          //Connect the handlers
          LongEventHandler h1 = new LongEventHandler();
          LongEventHandler h2 = new LongEventHandler();
					 disruptor.handleEventsWith(h1,h2);
        
          //Start the Disruptor,start all threads running
          disruptor.start();

          //Get the ring buffer form the Disruptor to be used for publishing.
          RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();

          //========================================================================
          final int threadCount = 10;
          CycliBarrier barrier=new CycliBarrier(threadCount);
          ExecutorService service = Executors.newCachedThreadPool();
          for(long i=0; i<threadCount; i++){
              final long threadNum = i; 
              service.submit(()->{
                  System.out.printf("Thread %s ready to start!\n",threadNum);
                  try{
                     barrier.await();
                  }catch(InterruptedException e){
                     e.printStackTrace();
                  }catch(BrokenBarrierException e){
                     e.printStackTrace();
                  }

                  for(int j=0; j<10;j++){
                      ringBuffer.publishEvent((event,sequence)->{
                          event.set(threadNum);
                          System.out.println("生产了"+threadNum);
                      });
                  }
              });
          }

          service.shutdown();
          //disruptor.shutdown();
          TimeUnit.SECONDS.sleep(3);
          System.out.println(LongEventHandler.count);
      }
}
```



还有disruptor最后一个问题，出了异常怎么处理

**消费者异常处理**

默认：disruptor.setDefaultExceptionHandler()

覆盖：disruptor.handleExceptionFor().with()

看下面代码，这这里方法里写了一个EventHandler是我们的消费者，在消费者里打印了event之后马上抛出了异常，当我们消费者出现异常之后你不能让整个线程停下来，有一个消费者出了异常那其他的消费者就不干活了，肯定不行。handleExceptionsFor为消费者指定Exception处理器 (h1).with后面是我们的ExceptionHandler出了异常之后该怎么办进行处理，重写三个方法，第一个是当产生异常的时候在这很简单直接打印出来了；第二个是handleOnStart如果启动的时候出异常；第三个handleOnShutdown你该怎么处理。

```java
package com.mashibing.disruptor;

import java.util.concurrent.Executor;
import java.util.concurrent.Executors;

import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.RingBuffer;
import com.lmax.disruptor.util.DaemonThreadFactory;
import java.nio.ByteBuffer;

public class Main07_ExceptionHandler{
    	public static void main(String[] args) thrwos Exception{
					
          //the factory for the event
          LongEvenFactory factory = new LongEventFactory();

          //Specify the of the ring buffer,must be power of 2.
          int bufferSize = 1024;

          //Construct the Disruptor
          Disruptor<LongEvent> disruptor = new Disruptor<>(factory,bufferSize, Executors.defaultThreadFactory(),ProducerType.MULTI,new SleepingWaitStrategy());

          //Connect the handlers
          EventHandler h1 = (event,sequence,end)->{
            	System.out.println("消费者出异常")；
          };
					 disruptor.handleEventsWith(h1);
        	
        	disruptor.handleExceptionsFor(h1).with(new ExceptionHandler<LongEvent>(){
            	@Override
            	public void handleEventException(Throwable throwable,long l,LongEvent longEvent){
                	throwable.printStackTrace();
              }
            
            	@Override
            	public void handleOnStartException(Throwable throwable){
                	System.out.println("Exception Start to Handle!");
              }
            
            	@Override
            	public void handleOnShutdownException(Throwable throwable){
                	System.out.println("Exception End to Handle!");
              }
          });
          
          //Start the Disruptor,start all threads running
          disruptor.start();

          //Get the ring buffer form the Disruptor to be used for publishing.
          RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();

          //========================================================================
          final int threadCount = 1;
          CycliBarrier barrier=new CycliBarrier(threadCount);
          ExecutorService service = Executors.newCachedThreadPool();
          for(long i=0; i<threadCount; i++){
              final long threadNum = i; 
              service.submit(()->{
                  System.out.printf("Thread %s ready to start!\n",threadNum);
                  try{
                     barrier.await();
                  }catch(InterruptedException e){
                     e.printStackTrace();
                  }catch(BrokenBarrierException e){
                     e.printStackTrace();
                  }

                  for(int j=0; j<10;j++){
                      ringBuffer.publishEvent((event,sequence)->{
                          event.set(threadNum);
                          System.out.println("生产了"+threadNum);
                      });
                  }
              });
          }

          service.shutdown();
          //disruptor.shutdown();
          TimeUnit.SECONDS.sleep(3);
          System.out.println(LongEventHandler.count);
      }
}
```

disruptor是一个环，然后这个环有多个生产者可以往里头生产，由于它是环形的设计效率会非常的高，我们写程序的时候是这样写的，首先你自己定义好Event消息的格式，然后定义消息工厂，消息工厂是用来初始化整个环的时候相应的一些位置上各种各样不同的消息先把它new出来，new出来之后先占好空间，我们在生产的时候只需要把这个位置上这个默认的这块空间拿出来往里头填值，填好值之后消费者就可以往里头消费了，消费完了生产者就可以继续往里头生产了，如果说你生产者消费的比较快，消费着消费的比较慢，满了怎么办，就是用各种各样的等待策略，消费者出了问题之后可以用ExceptionHandler来进行处理。

我们来复习一下第一期的多线程和高并发，大家对于多线程和高并发的一些课程有什么样的问题的话你也可以直接反馈给老师，比如下次更新的时候想听什么内容大家可以反馈给老师。下面我们稍微回顾一下

**多线程与高并发2019**

- 基本的概念

  什么是线程、线程现实、常用方法、线程状态、线程同步、synchronized锁升级等

- JUC同步工具

  cas、ReentrantLock可重入锁、Condition、Latch、CyclicBarrier等等

- 同步容器

  同步容器的演变、Maop/Set从无锁到同步、队列

- 线程池

  ThreadPool与Executor、ExecutorService、Executors、Callable、异步调用Futrre

- 高频面试加分项

  线程顺序执行控制

- JMH=java Microbenchmark Harness

  JMH解决什么问题、JMH插件安装、JMH吞吐量测试、JMH QPS/TPS测试

- 引用类型

  强引用与垃圾回收、软引用于缓存、弱引用与垃圾回收、虚引用与直接内存管理

- Disruptor

  目前性能最高的MQ，平庸架构师与高级架构师的区分、Legacy API、用Translator发布Event、使用Lambda表达式

